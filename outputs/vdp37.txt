name: vdp37
model: final.pt
seed: 42
gpu_number: 1
load: False
pretrained: False
pretrain: pretrain.pt
average: True
var_range: None
dim: [8, 8]
emb: [1024]
vdp: True
residual: independence
ordinal: False
batch_size: 32
optimizer: adam
learning_rate: 0.001
Tmax: 10
l2_reg: 0.0
kl_factor: 1e-10
focus: 0
no_zero: True
balance: False
epochs: 5
stop: 3
workers: 8
clip: 10
tol: 0.01
var_init: 0.01
dataset: pirats
nb_classes: 3
path: ./data/20200718_C_CONV.feather
split_ratio: 0.1
T_in: 40
T_out: 4
nb_lon: 50
nb_lat: 50
nb_alt: 5
state_dim: 6
max_ac: 674
weights: [1.0, 1.0, 1.0, 1.0]
n_patches: 7
patch_size: 4
predict_spot: False
spot: [39, 26, 3]
device: cuda
Initialize model
Trainable parameters: 175764122
Preprocessing training set
Building outputs
Preprocessing done
Preprocessing test set
Building outputs
Preprocessing done
Nb of timestamps: 3015
Nb of sequences: 2972
Trainset length: 2520
Testset length: 280
Max nb of a/c: 674
Start training
Epoch 1: 0/2520 0%, Loss: 0.15, NLL: 0.15, KL: 0.01
Epoch 1: 608/2520 24%, Loss: 0.13, NLL: 0.12, KL: 0.01
Epoch 1: 1216/2520 48%, Loss: 0.09, NLL: 0.08, KL: 0.01
Epoch 1: 1824/2520 72%, Loss: 0.06, NLL: 0.06, KL: 0.01
Epoch 1: 2432/2520 96%, Loss: 0.05, NLL: 0.04, KL: 0.01
Epoch: 1, Train Loss: 0.0522, NLL: 0.0430, KL: 0.0092
Test Loss: 0.0244, Accuracy: 37.23%, RMSE: 1.1185
Learning rate: [0.00092]
Epoch training time (s): 216.18971967697144
Saving model
Epoch 2: 0/2520 0%, Loss: 0.02, NLL: 0.01, KL: 0.01
Epoch 2: 608/2520 24%, Loss: 0.01, NLL: 0.00, KL: 0.01
Epoch 2: 1216/2520 48%, Loss: 0.01, NLL: 0.00, KL: 0.01
Epoch 2: 1824/2520 72%, Loss: 0.01, NLL: 0.00, KL: 0.01
Epoch 2: 2432/2520 96%, Loss: 0.01, NLL: 0.00, KL: 0.01
Epoch: 2, Train Loss: 0.0092, NLL: 0.0000, KL: 0.0092
Test Loss: 0.0115, Accuracy: 37.17%, RMSE: 1.1200
Learning rate: [0.0009400000000000001]
Epoch training time (s): 213.58809542655945
Saving model
Epoch 3: 0/2520 0%, Loss: 0.01, NLL: -0.00, KL: 0.01
Epoch 3: 608/2520 24%, Loss: 0.00, NLL: -0.00, KL: 0.01
Epoch 3: 1216/2520 48%, Loss: 0.00, NLL: -0.01, KL: 0.01
Epoch 3: 1824/2520 72%, Loss: 0.00, NLL: -0.01, KL: 0.01
Epoch 3: 2432/2520 96%, Loss: 0.00, NLL: -0.01, KL: 0.01
Epoch: 3, Train Loss: 0.0022, NLL: -0.0070, KL: 0.0092
Test Loss: 0.0042, Accuracy: 37.18%, RMSE: 1.1201
Learning rate: [0.00096]
Epoch training time (s): 242.28608226776123
Saving model
Epoch 4: 0/2520 0%, Loss: -0.00, NLL: -0.01, KL: 0.01
Epoch 4: 608/2520 24%, Loss: -0.00, NLL: -0.01, KL: 0.01
Epoch 4: 1216/2520 48%, Loss: -0.00, NLL: -0.01, KL: 0.01
Epoch 4: 1824/2520 72%, Loss: -0.00, NLL: -0.01, KL: 0.01
Epoch 4: 2432/2520 96%, Loss: -0.00, NLL: -0.01, KL: 0.01
Epoch: 4, Train Loss: -0.0005, NLL: -0.0097, KL: 0.0092
Test Loss: 0.0034, Accuracy: 37.17%, RMSE: 1.1201
Learning rate: [0.00098]
Epoch training time (s): 208.85316371917725
Saving model
Epoch 5: 0/2520 0%, Loss: 0.00, NLL: -0.01, KL: 0.01
Epoch 5: 608/2520 24%, Loss: -0.00, NLL: -0.01, KL: 0.01
Epoch 5: 1216/2520 48%, Loss: -0.00, NLL: -0.01, KL: 0.01
Epoch 5: 1824/2520 72%, Loss: -0.00, NLL: -0.01, KL: 0.01
Epoch 5: 2432/2520 96%, Loss: -0.00, NLL: -0.01, KL: 0.01
Epoch: 5, Train Loss: -0.0015, NLL: -0.0107, KL: 0.0092
Test Loss: 0.0016, Accuracy: 37.20%, RMSE: 1.1198
Learning rate: [0.001]
Epoch training time (s): 248.747394323349
Saving model
Saving final model
Best epoch: 5
Best loss: 0.001589
Training time (s): 1177.4173970222473
Saving train loss list
Saving val loss list
Saving train nll list
Saving val nll list
Saving kl list
Saving nll by class
Saving cutoff parameters
Start testing
Test: 0/280 (0%)
Test: 64/280 (22%)
Test: 128/280 (44%)
Test: 192/280 (67%)
Test: 248/280 (89%)
Test Loss: 0.001589, Accuracy: 37.20%, RMSE: 1.1198
Saving predictions
Saving ground truth
Saving variances
Saving correct variances
Saving incorrect variances
Done
